# Redshift

## 1. Redshift란? 
### 1-1. Redshift 한 줄 소개
AWS 에서 제공하는 페타바이트 규모의 엔터프라이즈급 **"완전 관리형"** **"데이터 웨어하우징 서비스"**. 데이터 웨어하우스와 데이터 레이크 전체에 걸쳐 간단하고 비용 효율적으로 모든 데이터를 분석할 수 있는 빠르고 확장 가능한 데이터 웨어하우스 서비스를 제공함. 
- MPP(Massively Parallel Processing, 대용량 병렬처리) 데이터베이스를 데이터웨어하우스로 제공

**완전 관리형 서비스란?**
-  관리, 모니터링 및 확장하는 데 필요한 일반적인 관리 작업 대부분을 자동화하여 관리해주는 서비스라는 의미. 즉, 데이터 웨어하우스 설치, 업그레이드, 패치, 수동백업을 신경쓸 필요가 없음
 
**데이터 웨어하우스란?**
- 보고서, 대시보드 및 분석 도구를 지원하는 데이터 저장소.
- 데이터를 효율적으로 저장하여 I/O를 최소화하고 빠른 속도로 동시에 쿼리 결과를 전달
- OLTP DB는  서비스에서 매우 중요. 분석용 DB는 분리하여 관리하는 움직임 생김 
- OLTP DB에서 주기적 데이터 덤프나 지속적 갱신 스트림으로 데이터 추출(Extract), 분석 친화적인 스키마로 변환(Transform), 정리하여 DW에 적재


### 1-2. Redshift의 구조

**1) 리더 노드**
- SQL 쿼리의 엔드포인트. 쿼리문 최적화 하는 역할 수행
- 메타데이터 저장
- 쿼리 실행을 관장

**2) 컴퓨트 노드**
- local columnar storage.
- 쿼리 로드, 백업, 클러스터 리사이즈 등을 직접 병렬/분산 처리하는 노드
- 각 노드에 데이터가 나누어서 저장되어 있음(중복해서 저장하는 것 X)

**3) 노드 타입은 두 가지 중에 선택할 수 있음**
- Dense Storage Node type: 스토리지 양이 많은 노드
- Dense Compute Node type스토리지 양은 좀 적지만 컴퓨팅이 빠른 노드


### 1-3. Redshift의 장점
**1) 다양한 기술 사용하여 디스크 I/O를 줄임**
- 열지향 스토리지로 데이터를 저장(리포팅, 분석은 칼럼별로 데이터를 사용하게 되니까)
- 데이터 압축 기술(2~4배 압축)
- 정렬을 통해 최소한의 데이터만 읽게 하는 기술(Zone Maps) 사용. 가령 날짜로 많이 쿼리하는 데이터는 날짜 기준으로 정렬하여 블록을 만들어둘 수 있음
- 네트웍, 외부 스토리지 사용하지 않고 로컬 스토리지 사용
- 한 번에 불러올 수 있는 데이터 블록을 매우 크게 만듦(일반 RDB = 16kb , Redshift는 = 1mb) 
- 쿼리, 로드, 추출, 백업 등 모두 분산/병렬처리

**2) 비용이 저렴함**
**3) 완전 관리형임**
- 1년 내내 안정적으로 사용하기보다는, 연말 월말에 리포트를 뽑을 때 큰 하드웨어 사용이 발생
- Redshift 를 계속 크게 사용하는 게 아니라  일시적으로 크기를 키워 데이터 처리 후, S3로 백업하여 두고,  Redshift 클러스터는 꺼버릴 수 있음. 
- 여러 리전에 복사해둘 수 있음(미국, 한국 두 곳에 카피해 둘 수 있음. 미국 지사에서 빠르게 데이터를 뽑아야 한다 --> 미국 지사 근처 리전에 복사해서 가져가고 데이터 불러서 분석)
- 기존 리전에서 문제가 발생하면 바로 백업해주는 관리도 포함

**4) 보안에 강함**
- VPC로 다른 클러스터는 절대 Redshift에 접속할 수 없음
- SQL 로 데이터를 입력, 출력할 수 있는 건 leader node뿐
- 데이터가 저장된 compute node는 아무나 접근 못함

**5) 빠르게 혁신 중이다**
- 모든 리전에서 제공하는 AWS 핵심 서비스
- 보안성, 쿼리 속도, 지원 데이터 형식 등을 빠르게 개선 중

**6) R, Python, 다양한 BI 툴과 같이 사용 가능**


## 2. 타사 서비스와의 공통점 및 차이점
- 레드시프트 - 전용 리소스 이용. 계산노드, 스토리지 일체화되어있음
- 빅쿼리(구글) - 공유 리소스 이용. 다수의 디스크에 데이터가 분산되어 있음. 


## 3. 데이터 사이언스 관점에서 활용 사례
- 아마존 닷컴: 기존 DW는 늘어나는 데이터를 빠르게 지원하지 못함. 
>시간당 일주일치 분석, 하둡은 시간당 한달치 분석했는데, 15개월치 1PB 데이터 처리에 14분 소요.
> 500억 로우 --> 로딩에 10분. 
>210억 로우 + 100억 로우 데이터 조인 후 쿼리 --> 2시간(하이브에선 3일)

- 스시로(일본 스시 체인):
> 380개 매장에서 스트림 라이브 데이터 수집 --> 태블로에 시각화 하기까지 5분 소요
> 실시간으로 수요를 체크하여 지점별 원재료 공급에 활용


## 4. 요금 부과 체계
Ref: https://aws.amazon.com/ko/redshift/pricing/
- 데이터가 500GB 미만인 경우, 고밀도 컴퓨팅 노드 유형
- 데이터가 500GB 이상인 경우, 성능이 주요 우선순위라면 고밀도 컴퓨팅 노드 유형
- 비용을 절감하고 싶거나 규모를 더 확장해야 하는 경우, 고밀도 스토리지 노드 유형

**1) 온디맨드**
- 약정 및 선결제 요금 없이 시간당 용량 요금을 지불
- 개발 또는 테스트 목적으로 환경을 비용 효율적으로 가동하고 제거

**2) 예약 인스턴스 요금**
- 프로덕션 워크로드가 안정적인 경우에 적합
- 클러스터 노드와 Amazon S3에 각각 하나씩, 두 가지 추가 데이터 사본이 포함된 요금
- AWS에서 백업, 내구성, 가용성, 보안, 모니터링 및 유지 관리를 대신해줌
- 현재 실행 중인 클러스터가 없더라도 관련된 선수금 및 시간당 비용이 청구
- 추가 요금 없이 월별 최대 2TB의 백업 스토리지를 사용
- 스토리지 크기를 초과하는 백업 스토리지 및 클러스터 종료 후 저장된 백업은 표준 [Amazon S3 요금](https://aws.amazon.com/s3/pricing/)으로 청구


**데이터 전송시 발생 비용 << 무슨 말인지 잘 모르겠음....**
- 작업의 백업, 복원, 로드 및 언로드를 위해 동일한 AWS 리전 내에서 Amazon Redshift와 Amazon S3 간에 전송되는 데이터에는 비용이 부과되지 않음
- Amazon Redshift에서 송수신되는 다른 모든 데이터에 대해서는 표준 [AWS 데이터 전송 요금](https://aws.amazon.com/ec2/pricing/)이 청구.
- Amazon VPC에서 Amazon Redshift 클러스터를 실행하는 경우 JDBC/ODBC를 통해 Amazon Redshift 클러스터 엔드포인트로 전송되는 데이터에 대해 표준 AWS 데이터 전송 요금이 부과
- 또한, [향상된 VPC 라우팅](https://docs.aws.amazon.com/redshift/latest/mgmt/enhanced-vpc-routing.html)을 사용하여 다른 리전에 있는 Amazon S3에 데이터를 언로드하면 표준 AWS 데이터 전송 요금이 발생

**3) Redshift Spectrum 요금**
- Amazon S3에 있는 엑사바이트 규모의 데이터에 SQL 쿼리를 직접 수행할 수 있음 
-  Redshift Spectrum에서 스캔한 바이트 수에 대해 비용이 부과
-  10GB의 데이터를 스캔하는 경우, 0.05 USD가 부과되고, 1테라바이트의 데이터를 스캔하는 경우, 5 USD부과
- 절약하는 방법: 압축 & 칼럼형식으로 변환!

- Redshift Spectrum  작동 예시
> 쿼리 날림 > 리더노드가 Spectrum으로 쿼리를 점길건지 판단 후 컴퓨트 노드로 쿼리 던짐 > 컴퓨트 노드는 사전에 정의해둔 데이터 카탈로그(메타 정보)를 읽어와서 레드시프트 스팩트럼으로 쿼리 던짐 > 스팩트럼이 S3에 있는 데이터 스캔 (스캔하는 데이터 사이즈별로 과금)>  s3에서 스팩트럼으로 데이터가 올라가서 조인, 필터링 등 수행 후 컴퓨트 노드로 전달 > 리더 노드가 합쳐서 보여줌

- Redshift Spectrum 요금 예시
> 크기가 같은 100개의 열이 있는 테이블이 Amazon S3에 압축이 안 된 텍스트 파일로 저장되어 있으며 전체 크기는 4테라바이트라고 가정해보겠습니다. 이 테이블의 한 열에서 데이터를 가져오도록 쿼리를 실행하면 Redshift Spectrum이 전체 파일을 스캔해야 합니다. 텍스트 형식은 분할될 수 없기 때문입니다. 이 쿼리는 4테라바이트를 스캔하고 요금은 20 USD(5 USD/TB * 4TB = **20 USD** )입니다.

> GZIP을 사용해 파일을 압축하면 4:1의 압축 이득을 얻을 수 있습니다. 이 경우 1테라바이트 크기의 압축 파일이 생깁니다. Redshift Spectrum은 전체 파일을 스캔해야 하지만 크기가 1/4이므로 요금의 1/4인 5 USD만 지불하면 됩니다(5 USD/TB * 1TB =  **5 USD** ).

> 파일을 압축하고 Apache Parquet와 같은 컬럼 형식으로 변환하면 4:1 압축 이득이 생겨 압축 파일 크기가 1테라바이트가 됩니다. 위와 동일한 쿼리를 사용하면 Redshift Spectrum이 Parquet 파일에서 한 열만 스캔하면 됩니다. 이 쿼리의 비용은 0.05 USD입니다(5 USD/TB * 1TB 파일 크기 * 1/100열 또는 스캔한 총 10기가바이트 =  **0.05 USD** ).


Ref : 
https://www.youtube.com/watch?v=6zB16Mr7lDs&t=3368s ( AWS 5월 웨비나 | Amazon Redshift Deep Dive (양승도 솔루션즈아키텍트)  / 2017. 5. 30.)
https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=171846800
https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=140018308
